<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=768"/>
  <meta name="author" content="Tobias Stamm"/>
  <link rel="stylesheet" type="text/css" href="css.css"/>
  <title>Bit Fiddle</title>
</head>
<body>

<h1>Bit Fiddle</h1>

<article>
<header>
<h2>What does this application do?</h2>
</header>
<ul>
<li>Conversion of arbitrarily large Integer-Numbers in the decimal-, hexadecimal- and binary system and in ASCII-Characters.</li>
<li>Computation of Ones and Twos Complement.</li>
<li>Exchange of bytes of the input to convert between little and big endian.</li>
<li>Display of a simple ASCII table with additional information to each character.</li>
</ul>
</article>



<article>
<header>
<h2>UI elements of the main window</h2>
</header>
<p>The main window exists in two variants: A large and a mini version. To switch between the two versions, press the green button in the title bar or select the appropriate command in the window menu.</p>

<p>The main window is divided in to the entry fields above, the output fields in the middle and the settings below.</p>
<p>The input and output fields are arrangen in a table, whereas the columns represent the different bases and the rows represent the differen byte sizes: 8, 16, 32, 64 and n Bytes. With n Bytes, the result will automatically use as many bytes as neede for an unsigned number.</p>
<p>When inputting numbers, only very specific digits are parsed. Any character which is not an allowed digit will simply be ignored (as well as the negativ sign! See below).</p>
<ul>
<li><b>Dec</b>: Decimal numbers. Numbers with base 10, like those, humans normally work with. Digits: 0123456789</li>
<li><b>Hex</b>: Hexadecimal numbers. Numbers with base 16, often seen in computer programs. Digits: 0123456789abcdef as well as ABCDEF</li>
<li><b>Bin</b>: Binary numbers. Numbers with base 2, only two values are allowed. Digits 01. Additionally, also the characters oO, iI and L are allowed.</li>
<li><b>Asc</b>: ASCII-Characters. Numbers are assumed to be a sequence of 8-Bit-Characters and are displayed as ASCII-7 with leading 0. Any character of the ASCII charset is available. Numbers which do not correspond to a valid ASCII character will be displayed with a question mark ?</li>
</ul>

<p>In the large window, there are additional sessings which can be selected directly or by using the appropriate menu command:</p>
<ul>
<li><b>Little ↔︎ Big</b>: Exchange of bytes of the input field to convert between little- and big-endian. Beware: Only use this if you know what it is for.</li>
<li><b>Unsigned</b>: The input is interpreted as an unsigned number and will be converted directly into all output numbers.</li>
<li><b>Ones complement</b>: The input will be interpreted as an unsigned number, will be converted using the ones complement and will then be converted to all output numbers.</li>
<li><b>Twos complement</b>: The input will be interpreted as an unsigned number, will be converted using the twos complement and will then be converted to all output numbers.</li>
<li><b>ASCII</b>: Displays a simple ASCII table in a separate window with additional information to each character</li>
<li><b>Menu Settings</b>: Different settings concerning showing and hiding the different windows.</li>
</ul>
</article>


<article>
<header>
<h2>UI elements of the ASCII window</h2>
</header>
<p>The window is divided into the ASCII characters above and the settings below.</p>
<p>By hovering over the differen characters, additional informations will be displayed in the section below.</p>
<ul>
<li><b>Escape / Code</b> In programming languages with C syntax, certain characters can be displayed using Escape codes. Use this control to switch between the escape codes or the official ISO codes of the first 32 Characters.</li>
<li><b>Hex / Dec</b>: Switch between hexadecimal or decimal numbering of the characters.</li>
</ul>
</article>


<article>
<header>
<h2>Preferences</h2>
</header>
<p>At application start:</p>
<ul>
<li><b>hide ASCII window</b>: The window with the ASCII characters will be hidden upon application start.</li>
<li><b>Reset conversion</b>: The conversion settings will be reset to unsigned computation without endianness switch at each application restart.</li>
</ul>

<p>Keep windows in foreground:</p>
<ul>
<li><b>Extensive Window</b>: The large window will be kept in front of all applications.</li>
<li><b>Mini-Version</b>: The mini window will be kept in front of all applications.</li>
</ul>
</article>


<article>
<header>
<h2>Why isn't the twos complement negative?</h2>
</header>
<p>There is a large confusion about what exactly the twos complement is. Many people think the twos complement inside a computer is the same as a negative number. This is not true.</p>
<p>We humans compute numbers using the decimal system with the digits 0 to 9. To express a negative number, we have an additional character> The negativ sign. A computer though can only express numbers with two digits 0 and 1 and has no additional character for negative numbers. Therefore, he must somehow encode a negative number with 0 and 1 such that both positive as well as negative numbers can be stored. Nowadays, the most common way to do this is using the twos complement. of the absolute value.</p>
<p>The twos complement therefore depicts the conversion of an absolute value, stored as a binary value. How to finally interpret such a binary value though can not be predicted. One can not distinguish between signed or unsigned values. For computing the twos complement, such interpretation is irrelevant as it simply converts the binary digits using a clearly specified method.</p>

<p>There are rather a lot of different possibilities to convert binary values, interpret them, shorten or extend them as well as display them. If all possibilities would have been implemented in Bit Fiddle, the UI would have become very complex. The developer decided to provide only the most common conversions. Some cases are therefore hard to achieve but these cases are usually the trivial cases which no developer bothers to enter digits into a program. To understand, what is going on in Bit Fiddle, here is a complete description of the conversion process:</p>

<p><b>The exact process of converting numbers</b></p>

<ul>
<li>First, the input values (Dec, Hex, Bin or Asc) are converted into an internal format consisting of multiple bits. Only the characters listed above will be used, all the rest will be discarded. A negative decimal number as input therefore will never be interpreted as negative as the negative sign is ignored. Internally, the number of bits to store the input is arbitrary high but always consist of the exact number of bytes which would be required to store the entered value as an unsigned value. This means the number of bits resulting is always divisible by 8.</li>
<li>After that, if the <q>Little ↔︎ Big</q> option is activated, the bytes are reversed.</li>
<li>Then the selected conversion takes place, meaning <q>Unsigned</q> (Which does nothing), <q>Ones complement</q> or <q>Twos complement</q>.</li>
<li>After that, the RESULTING bits are packed into the different output format widths.
  <ul>
    <li>If the internal bitcount is higher than the number of bits available in the output format, the higher-order bits are cut off. For example the internal number 0b00110011 10101010 results in the 8-bit output 0b10101010. This corresponds exactly to the implicit integer conversion mechanism of many programming languages.</li>
    <li>If the internal bitcount uses less bits than the output format, the internal bits will be extended ARITHMETICALLY. This means, that any internal number which apperas to be SIGNED, will be interpreted as such. For example the internal number 0b10101010 will result in the 16 bit output 0b11111111 10101010. This has been designed in Bit Fiddle this way because the non-arithmetical conversion (the logical conversion by simply adding zeros as high order bits) is trivial and will not result in any more insight. It is assumed that an user knows that and that he will see immediately if the numer was extended arithmetically.</li>
  </ul>
</li>
<li>After that, the different output widths will be converted into the differen base systems. This results in decimal numbers, hexadecimal numbers, binary numbers and ASCII strings.
  <ul>
    <li>Decimal numbers will be displayed as groups of 3 using the decimal digits 0 to 9 separated by a space. In case of conversion using the ones complement, no output will be generated. In case the conversion of the twos complement is active, the number will be interpreted as signed and hence will be expressed with a negative sign, if applicable.</li>
    <li>Hexadecimal numbers will be displayed using pairwise hexadecimal digits, separated by a space. The letters will be printed in lower case.</li>
    <li>Binary numbers will be displayed using groups of 8, consisting of 0 and 1 and separated by a space.</li>
    <li>ASCII strings will be expressed as pure 7 bit ASCII characters whereas the highes order bit is set to 0. Bytes which do not result in a valid ASCII character will be displayed with a questionmark ?</li>
  </ul>
</li>
</ul>

<p>This conversion should cover all non-trivial conversions of your everyday work with integer numbers.</p>

<p>Beware, as the input will always be assumed to be unsigned, it is not possible to enter a signed number using hexadecimal numbers and read out the negative value as a decimal number. For those interesten in that, they should convert the number using the twos complement and add a negative sign to the resulting number.</p>
</article>






</body></html>
